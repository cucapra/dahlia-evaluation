{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Script\n",
    "\n",
    "This script is used to regenerate all graphs reported in the paper \"Predictable Accelerator Design with Time-Sensitive Affine types\". The script uses data committed in the repository to generate the results. It **does not** recollect the data.\n",
    "\n",
    "There are four graphs in the paper.\n",
    "\n",
    "1. Figure 4: Sensitivity analysis of unrolling and partitioning.\n",
    "2. Figure 7: Exhaustive design space exploration for gemm-blocked.\n",
    "3. Figure 8: Qualitative study of MachSuite benchmarks.\n",
    "4. Figure 9: Resource Utilization for gemm-ncubed in Spatial.\n",
    "\n",
    "The script will regenerate all the graphs. We welcome reviewer to perform further analysis/explore the data collected in the paper. At the end of the script, we optionally demonstrate one such analysis on the data we collected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "### Exhaustive Design Space Exploration (fig. 8)\n",
    "\n",
    "This experiment collected data for 32,000 configurations of a blocked matrix-matrix multiply kernel. We partition\n",
    "the data into three sets:\n",
    "\n",
    "1. Set of Pareto-optimal points.\n",
    "2. Set of points accepted by Dahlia.\n",
    "3. Set of points that are Pareto optimal and accepted by Dahlia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from benchmarking.plotting import plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Location for all figures\n",
    "FIG_DIR = \"all-figures/\"\n",
    "# DPI setting\n",
    "DPI = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collected data.\n",
    "exhaustive_dse_points = pd.read_csv('exhaustive-dse/data/summary.csv')\n",
    "\n",
    "# Names of configurations accepted by Dahlia.\n",
    "exhaustive_dahlia_accepted = pd.read_csv('exhaustive-dse/data/dahlia-points.csv')\n",
    "\n",
    "# Remove prefix stem from benchmark names\n",
    "exhaustive_dse_points.bench = \\\n",
    "    exhaustive_dse_points.apply(lambda row: row.bench.replace('gemm-dse:gemm-', ''), axis=1)\n",
    "exhaustive_dahlia_accepted = \\\n",
    "    exhaustive_dahlia_accepted.apply(lambda row: row.bench.replace('dahlia-gemm-', ''), axis=1)\n",
    "\n",
    "# Coerce columns into numeric types\n",
    "for key in exhaustive_dse_points.columns:\n",
    "    if key != 'bench':\n",
    "        exhaustive_dse_points[key] = pd.to_numeric(exhaustive_dse_points[key], errors='coerce')\n",
    "\n",
    "# Remove invalid rows.\n",
    "exhaustive_dse_points = exhaustive_dse_points[exhaustive_dse_points.notnull().all(axis=1)].reset_index()\n",
    "\n",
    "# Sanity check: latency estimates are tight.\n",
    "for idx in range(len(exhaustive_dse_points)):\n",
    "    assert exhaustive_dse_points.est_min_lat[idx] == exhaustive_dse_points.est_max_lat[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exhaustive_dahlia_points = \\\n",
    "  exhaustive_dse_points[exhaustive_dse_points[\"bench\"].isin(exhaustive_dahlia_accepted.to_numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources to calculate pareto front for.\n",
    "resources = [ 'est_' + key for key in [ 'ff', 'dsp', 'bram', 'lut' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pareto points\n",
    "# From: https://stackoverflow.com/questions/32791911/fast-calculation-of-pareto-front-in-python\n",
    "\n",
    "def find_pareto(costs):\n",
    "    \"\"\"\n",
    "    Find the pareto-efficient points\n",
    "    :param costs: An (n_points, n_costs) array\n",
    "    :return: A (n_points, ) boolean array, indicating whether each point is Pareto efficient\n",
    "    \"\"\"\n",
    "    is_efficient = np.ones(costs.shape[0], dtype = bool)\n",
    "    for i, c in enumerate(costs):\n",
    "        (before, after) = costs[:i], costs[i+1:]\n",
    "        # All points such that there is no point which has at least one objective minimized better and other objectives at least equal.\n",
    "        is_efficient[i] = np.all(np.logical_not(np.logical_and(np.all(before <= c, axis=1), np.any(before < c, axis=1)))) and \\\n",
    "                          np.all(np.logical_not(np.logical_and(np.all(after <= c, axis=1), np.any(after < c, axis=1))))\n",
    "    return is_efficient\n",
    "\n",
    "def get_pareto():\n",
    "    opts = find_pareto(exhaustive_dse_points[['est_compute_lat'] + resources].to_numpy())\n",
    "    opt_idxs = np.where(opts == True)\n",
    "    return exhaustive_dse_points.iloc[opt_idxs]\n",
    "\n",
    "\n",
    "exhaustive_pareto_points = get_pareto()\n",
    "\n",
    "# Number of true pareto trade off points\n",
    "print(\"[Exhaustive DSE] Number of Pareto points: \", len(exhaustive_pareto_points[['est_compute_lat'] + resources].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dahlia points not in pareto frontier\n",
    "def get_dahlia_pareto():    \n",
    "    non_pareto_dahlia = set(exhaustive_dahlia_points.bench).difference(set(exhaustive_pareto_points.bench))\n",
    "    pareto_dahlia = set(exhaustive_dahlia_points.bench).intersection(set(exhaustive_pareto_points.bench))\n",
    "    return (\n",
    "        exhaustive_dse_points[exhaustive_dse_points.bench.isin(non_pareto_dahlia)],\n",
    "        exhaustive_dse_points[exhaustive_dse_points.bench.isin(pareto_dahlia)]\n",
    "    )\n",
    "\n",
    "exhaustive_non_pareto_dahlia_points, exhaustive_pareto_dahlia_points = get_dahlia_pareto()\n",
    "\n",
    "print(\"[Exhaustive DSE] Dahlia non pareto configurations: \", \n",
    "      len(exhaustive_non_pareto_dahlia_points[['est_compute_lat'] + resources].drop_duplicates()))\n",
    "print(\"[Exhaustive DSE] Pareto pareto configurations: \", \n",
    "      len(exhaustive_pareto_dahlia_points[['est_compute_lat'] + resources].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_exhaustive():\n",
    "    sns.set()\n",
    "\n",
    "    pal = sns.color_palette('colorblind', 8)\n",
    "\n",
    "    # Settings\n",
    "    groups = [\n",
    "        {'label': 'All', 'data': exhaustive_dse_points, 'color': pal[-1], 'marker': 'o', 'alpha': 0.05},\n",
    "        {'label': 'Pareto', 'data': exhaustive_pareto_points, 'color': pal[1], 'marker': 's', 'alpha': 0.5},\n",
    "        {'label': 'Dahlia', 'data': exhaustive_dahlia_points, 'color': pal[2], 'marker': 'X', 'alpha': 0.2},\n",
    "        {'label': 'Non pareto Dahlia', 'data': exhaustive_non_pareto_dahlia_points, 'color': pal[2], 'marker': 'X', 'alpha': 0.2},\n",
    "        {'label': 'Pareto points accepted by Dahlia', 'data': exhaustive_pareto_dahlia_points, 'color': pal[2], 'marker': 'X', 'alpha': 0.2}\n",
    "    ]\n",
    "\n",
    "    to_plot = [\n",
    "        {'prefix': 'only-pareto', 'groups': [0, 1]},\n",
    "        {'prefix': 'dahlia-pareto', 'groups': [0, 1, 4]},\n",
    "        {'prefix': 'dahlia-non-pareto', 'groups': [0,3]}\n",
    "    ]\n",
    "\n",
    "    for plot_info in to_plot:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca()\n",
    "        for g in plot_info['groups']:\n",
    "            group = groups[g]\n",
    "            sns.scatterplot(x='est_compute_lat', \n",
    "                            y='est_lut', data=group['data'], \n",
    "                            color=group['color'], \n",
    "                            marker=group['marker'],\n",
    "                            label=group['label'],\n",
    "                            rasterized=True)\n",
    "\n",
    "        ax.get_xaxis().set_major_formatter(\n",
    "            matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x / 10 ** 6), ',')))\n",
    "        ax.get_yaxis().set_major_formatter(\n",
    "            matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "        ax.set_xlabel('Estimated latency (millions of cycles)')\n",
    "        ax.set_ylabel('Estimate LUTs')\n",
    "        fig.tight_layout()\n",
    "        name = FIG_DIR + \"gemm-blocked-dse-{}.pdf\".format(plot_info['prefix'])\n",
    "        print(\"[Exhaustive DSE] Generating \" + name)\n",
    "        fig.savefig(name, dpi=DPI)\n",
    "        \n",
    "plot_exhaustive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Sensitivity Analysis (Fig 4)\n",
    "\n",
    "Figure 4 in Section 2 analyzes the effects of varying unrolling and partitioning independently of each other. There are three figures:\n",
    "\n",
    "1. Varying unrolling with no partitioning.\n",
    "2. Varying unrolling with constant partitioning.\n",
    "3. Varying unrolling and paritioning in lockstep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data locations\n",
    "\n",
    "sensitivity_no_part = \\\n",
    "  pd.read_csv('./sensitivity-analysis/no-partition-unroll/summary.csv').sort_values(by='unroll').reset_index()\n",
    "sensitivity_const_part = \\\n",
    "  pd.read_csv('./sensitivity-analysis/const-partition-unroll/summary.csv').sort_values(by='unroll').reset_index()\n",
    "sensitivity_lockstep = \\\n",
    "  pd.read_csv('./sensitivity-analysis/lockstep-partition-and-unroll/summary.csv').sort_values(by='partition').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sensitivity_plots():\n",
    "    # No partition plot.\n",
    "    print('[Sensitivity Analysis] Generating no partition graphs.')\n",
    "    plots.make_absolute_plots(\n",
    "        sensitivity_no_part,\n",
    "        x_key = 'unroll',\n",
    "        y_keys = ['runtime_avg', 'lut_used'],\n",
    "        group_by = lambda x: 0,\n",
    "        x_label = 'Unrolling factor (no partitioning)',\n",
    "        fig_prefix = 'no-partition-unrolling',\n",
    "        dpi = DPI,\n",
    "        fig_dir = FIG_DIR,\n",
    "        )\n",
    "    \n",
    "    # Constant partitioning\n",
    "    print('[Sensitivity Analysis] Generating constant partition graphs.')\n",
    "    plots.make_sec2_plot(\n",
    "        df=sensitivity_const_part,\n",
    "        x_key='unroll',\n",
    "        x_label = 'Unrolling factor (partitioning = 8)',\n",
    "        factor = 8,\n",
    "        fig_prefix = 'const-partition-unroll',\n",
    "        legend = 'lut_used',\n",
    "        dpi = DPI,\n",
    "        fig_dir = FIG_DIR,\n",
    "    )\n",
    "    \n",
    "    # Lockstep partitioning and unrolling\n",
    "    print('[Sensitivity Analysis] Generating lockstep partition graphs.')\n",
    "    plots.make_sec2_plot(\n",
    "        df=sensitivity_lockstep,\n",
    "        x_key = 'partition',\n",
    "        x_label = 'Partitioning and Unrolling factor',\n",
    "        fig_prefix = 'const-len-partition-and-unroll',\n",
    "        dpi=DPI,\n",
    "        fig_dir = FIG_DIR)\n",
    "\n",
    "\n",
    "make_sensitivity_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "### Qualitative Evaluation (fig 8)\n",
    "\n",
    "The qualitative evaluation consists of parameter sweeps over three MachSuite benchmarks:\n",
    "\n",
    "1. stencil-2d\n",
    "2. md-knn\n",
    "3. md-grid\n",
    "\n",
    "For each benchmark, we generated several configurations and ran estimation for the benchmarks accepted by Dahlia. We **did not** run estimation for all possible configurations--just the ones accepted by Dahlia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_X = {\"scale_fun\": lambda x: int(x / 100), \"scale_label\": \"Hundreds of cycles\"}\n",
    "\n",
    "RESOURCES = ['bram_used', 'dsp48_used', 'ff_used', 'lut_used', 'avg_latency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark files\n",
    "qual_benchs = ['md-knn-summary', 'md-grid-summary', 'stencil2d-inner-summary']\n",
    "\n",
    "# Dataframes with all the data.\n",
    "qual_dfs = { bench_name : pd.read_csv(f\"qualitative-study/data/{bench_name}.csv\") for bench_name in qual_benchs }\n",
    "\n",
    "# Calculate average latencies for each benchmark.\n",
    "for key in qual_benchs:\n",
    "    qual_dfs[key]['avg_latency'] = ((qual_dfs[key]['min_latency'] + qual_dfs[key]['max_latency']) /  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stencil2d():\n",
    "    df = qual_dfs['stencil2d-inner-summary']\n",
    "    res = 'ur_loop2'\n",
    "\n",
    "    opts = find_pareto(df[RESOURCES].to_numpy())\n",
    "    pareto = df.iloc[opts]\n",
    "    \n",
    "    print(f'[Qualitative Study] Accepted Pareto points for stencil2d: {len(pareto)}/{len(df)}')\n",
    "\n",
    "    def group(idx):\n",
    "        return df.iloc[idx][res]\n",
    "\n",
    "    plots.make_qual_plot(\n",
    "        pareto,\n",
    "        x_data = {'key': 'avg_latency', 'label': 'Average Latency'},\n",
    "        y_data = {'key': 'lut_used', 'label': 'LUTs Used'},\n",
    "        group_by = group,\n",
    "        legend=\"Inner Unroll\",\n",
    "        fig_prefix = \"stencil-inner-2d-inner-unroll\",\n",
    "        scale_x = SCALE_X,\n",
    "        fig_dir = FIG_DIR,\n",
    "        dpi=DPI,\n",
    "    )\n",
    "    \n",
    "plot_stencil2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers from md_knn\n",
    "\n",
    "In the graph above, the points on the extreme right trade-off a lot of latency for reducing the LUT count by a bit. In the paper, we decided to not show these points **but we explicitly call this out in the prose of the paper**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_md_knn():\n",
    "    df = qual_dfs['md-knn-summary']\n",
    "    df = df[df.avg_latency < 100000].reset_index()\n",
    "    res = 'ur_loop1'\n",
    "\n",
    "    opts = find_pareto(df[RESOURCES].to_numpy())\n",
    "    pareto = df.iloc[opts]\n",
    "    \n",
    "    print(f'[Qualitative Study] Accepted Pareto points for md-knn: {len(pareto)}/{len(df)}')\n",
    "    \n",
    "    def group(idx):\n",
    "        return df.iloc[idx][res]\n",
    "            \n",
    "    plots.make_qual_plot(\n",
    "        pareto,\n",
    "        x_data = {'key': 'avg_latency', 'label': 'Average Latency'},\n",
    "        y_data = {'key': 'lut_used', 'label': 'LUTs Used'},\n",
    "        group_by = group,\n",
    "        legend='Outer Unroll',\n",
    "        fig_prefix = \"md-knn-outer-unroll\",\n",
    "        scale_x = SCALE_X,\n",
    "        fig_dir = FIG_DIR,\n",
    "        dpi=DPI,\n",
    "    )\n",
    "\n",
    "plot_md_knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_md_grid():\n",
    "    df = qual_dfs['md-grid-summary']\n",
    "    res = 'B0Y_UR'\n",
    "\n",
    "    opts = find_pareto(df[RESOURCES].to_numpy())\n",
    "    pareto = df.iloc[opts]\n",
    "    \n",
    "    print(f'[Qualitative Study] Accepted Pareto points for md-grid: {len(pareto)}/{len(df)}')\n",
    "\n",
    "    def group(idx):\n",
    "        return df.iloc[idx][res]\n",
    "\n",
    "    plots.make_qual_plot(\n",
    "        pareto,\n",
    "        x_data = {'key': 'avg_latency', 'label': 'Average Latency'},\n",
    "        y_data = {'key': 'lut_used', 'label': 'LUTs Used'},\n",
    "        group_by = group,\n",
    "        legend=\"Middle Unroll\",\n",
    "        fig_prefix = \"md-grid-middle-unroll\",\n",
    "        scale_x = SCALE_X,\n",
    "        fig_dir = FIG_DIR,\n",
    "        dpi=DPI,\n",
    "    )\n",
    "    \n",
    "plot_md_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
