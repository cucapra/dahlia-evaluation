{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Script\n",
    "\n",
    "This script is used to regenerate all graphs reported in the paper \"Predictable Accelerator Design with Time-Sensitive Affine types\". The script uses data committed in the repository to generate the results. It **does not** regenerate the data.\n",
    "\n",
    "There are four graphs in the paper.\n",
    "\n",
    "1. Figure 4: Sensitivity analysis of unrolling and partitioning.\n",
    "2. Figure 7: Exhaustive design space exploration for gemm-blocked.\n",
    "3. Figure 8: Qualitative study of MachSuite benchmarks.\n",
    "4. Figure 9: Resource Utilization for gemm-ncubed in Spatial.\n",
    "\n",
    "The script will regenerate all the graphs. We welcome reviewers to perform further analysis/explore the data collected in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "### Exhaustive Design Space Exploration (fig. 8)\n",
    "\n",
    "This experiment collected data for 32,000 configurations of a blocked matrix-matrix multiply kernel. We partition\n",
    "the data into three sets:\n",
    "\n",
    "1. Set of Pareto-optimal points.\n",
    "2. Set of points accepted by Dahlia.\n",
    "3. Set of points that are Pareto optimal and accepted by Dahlia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from benchmarking.plotting import plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Location for all figures\n",
    "FIG_DIR = \"all-figures/\"\n",
    "# DPI setting\n",
    "DPI = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collected data.\n",
    "exhaustive_dse_points = pd.read_csv('exhaustive-dse/data/summary.csv')\n",
    "\n",
    "# Names of configurations accepted by Dahlia.\n",
    "exhaustive_dahlia_accepted = pd.read_csv('exhaustive-dse/data/dahlia-points.csv')\n",
    "\n",
    "# Remove prefix stem from benchmark names\n",
    "exhaustive_dse_points.bench = \\\n",
    "    exhaustive_dse_points.apply(lambda row: row.bench.replace('gemm-dse:gemm-', ''), axis=1)\n",
    "exhaustive_dahlia_accepted = \\\n",
    "    exhaustive_dahlia_accepted.apply(lambda row: row.bench.replace('dahlia-gemm-', ''), axis=1)\n",
    "\n",
    "# Coerce columns into numeric types\n",
    "for key in exhaustive_dse_points.columns:\n",
    "    if key != 'bench':\n",
    "        exhaustive_dse_points[key] = pd.to_numeric(exhaustive_dse_points[key], errors='coerce')\n",
    "\n",
    "# Remove invalid rows.\n",
    "exhaustive_dse_points = exhaustive_dse_points[exhaustive_dse_points.notnull().all(axis=1)].reset_index()\n",
    "\n",
    "# Sanity check: latency estimates are tight.\n",
    "for idx in range(len(exhaustive_dse_points)):\n",
    "    assert exhaustive_dse_points.est_min_lat[idx] == exhaustive_dse_points.est_max_lat[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exhaustive_dahlia_points = \\\n",
    "  exhaustive_dse_points[exhaustive_dse_points[\"bench\"].isin(exhaustive_dahlia_accepted.to_numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources to calculate pareto front for.\n",
    "resources = [ 'est_' + key for key in [ 'ff', 'dsp', 'bram', 'lut' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pareto points\n",
    "# From: https://stackoverflow.com/questions/32791911/fast-calculation-of-pareto-front-in-python\n",
    "\n",
    "def find_pareto(costs):\n",
    "    \"\"\"\n",
    "    Find the pareto-efficient points\n",
    "    :param costs: An (n_points, n_costs) array\n",
    "    :return: A (n_points, ) boolean array, indicating whether each point is Pareto efficient\n",
    "    \"\"\"\n",
    "    is_efficient = np.ones(costs.shape[0], dtype = bool)\n",
    "    for i, c in enumerate(costs):\n",
    "        (before, after) = costs[:i], costs[i+1:]\n",
    "        # All points such that there is no point which has at least one objective minimized better and other objectives at least equal.\n",
    "        is_efficient[i] = np.all(np.logical_not(np.logical_and(np.all(before <= c, axis=1), np.any(before < c, axis=1)))) and \\\n",
    "                          np.all(np.logical_not(np.logical_and(np.all(after <= c, axis=1), np.any(after < c, axis=1))))\n",
    "    return is_efficient\n",
    "\n",
    "def get_pareto():\n",
    "    opts = find_pareto(exhaustive_dse_points[['est_compute_lat'] + resources].to_numpy())\n",
    "    opt_idxs = np.where(opts == True)\n",
    "    return exhaustive_dse_points.iloc[opt_idxs]\n",
    "\n",
    "\n",
    "exhaustive_pareto_points = get_pareto()\n",
    "\n",
    "# Number of true pareto trade off points\n",
    "print(\"[Exhaustive DSE] Number of Pareto points: \", len(exhaustive_pareto_points[['est_compute_lat'] + resources].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dahlia points not in pareto frontier\n",
    "def get_dahlia_pareto():    \n",
    "    non_pareto_dahlia = set(exhaustive_dahlia_points.bench).difference(set(exhaustive_pareto_points.bench))\n",
    "    pareto_dahlia = set(exhaustive_dahlia_points.bench).intersection(set(exhaustive_pareto_points.bench))\n",
    "    return (\n",
    "        exhaustive_dse_points[exhaustive_dse_points.bench.isin(non_pareto_dahlia)],\n",
    "        exhaustive_dse_points[exhaustive_dse_points.bench.isin(pareto_dahlia)]\n",
    "    )\n",
    "\n",
    "exhaustive_non_pareto_dahlia_points, exhaustive_pareto_dahlia_points = get_dahlia_pareto()\n",
    "\n",
    "print(\"[Exhaustive DSE] Dahlia non-pareto configurations: \", \n",
    "      len(exhaustive_non_pareto_dahlia_points[['est_compute_lat'] + resources].drop_duplicates()))\n",
    "print(\"[Exhaustive DSE] Dahlia pareto configurations: \", \n",
    "      len(exhaustive_pareto_dahlia_points[['est_compute_lat'] + resources].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_exhaustive():\n",
    "    sns.set()\n",
    "\n",
    "    pal = sns.color_palette('colorblind', 8)\n",
    "\n",
    "    # Settings\n",
    "    groups = [\n",
    "        {'label': 'All', 'data': exhaustive_dse_points, 'color': pal[-1], 'marker': 'o', 'alpha': 0.05},\n",
    "        {'label': 'Pareto', 'data': exhaustive_pareto_points, 'color': pal[1], 'marker': 's', 'alpha': 0.5},\n",
    "        {'label': 'Dahlia', 'data': exhaustive_dahlia_points, 'color': pal[2], 'marker': 'X', 'alpha': 0.2},\n",
    "        {'label': 'Non pareto Dahlia', 'data': exhaustive_non_pareto_dahlia_points, 'color': pal[2], 'marker': 'X', 'alpha': 0.2},\n",
    "        {'label': 'Pareto points accepted by Dahlia', 'data': exhaustive_pareto_dahlia_points, 'color': pal[2], 'marker': 'X', 'alpha': 0.2}\n",
    "    ]\n",
    "\n",
    "    to_plot = [\n",
    "        {'prefix': 'only-pareto', 'groups': [0, 1]},\n",
    "        {'prefix': 'dahlia-pareto', 'groups': [0, 1, 4]},\n",
    "        {'prefix': 'dahlia-non-pareto', 'groups': [0,3]}\n",
    "    ]\n",
    "\n",
    "    for plot_info in to_plot:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca()\n",
    "        for g in plot_info['groups']:\n",
    "            group = groups[g]\n",
    "            sns.scatterplot(x='est_compute_lat', \n",
    "                            y='est_lut', data=group['data'], \n",
    "                            color=group['color'], \n",
    "                            marker=group['marker'],\n",
    "                            label=group['label'],\n",
    "                            rasterized=True)\n",
    "\n",
    "        ax.get_xaxis().set_major_formatter(\n",
    "            matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x / 10 ** 6), ',')))\n",
    "        ax.get_yaxis().set_major_formatter(\n",
    "            matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "        ax.set_xlabel('Estimated latency (millions of cycles)')\n",
    "        ax.set_ylabel('Estimate LUTs')\n",
    "        fig.tight_layout()\n",
    "        name = FIG_DIR + \"gemm-blocked-dse-{}.pdf\".format(plot_info['prefix'])\n",
    "        print(\"[Exhaustive DSE] Generating \" + name)\n",
    "        fig.savefig(name, dpi=DPI)\n",
    "        \n",
    "plot_exhaustive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Sensitivity Analysis (Fig 4)\n",
    "\n",
    "Figure 4 in Section 2 analyzes the effects of varying unrolling and partitioning independently of each other. There are three figures:\n",
    "\n",
    "1. Varying unrolling with no partitioning.\n",
    "2. Varying unrolling with constant partitioning.\n",
    "3. Varying unrolling and paritioning in lockstep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data locations\n",
    "\n",
    "sensitivity_no_part = \\\n",
    "  pd.read_csv('./sensitivity-analysis/no-partition-unroll/summary.csv').sort_values(by='unroll').reset_index()\n",
    "sensitivity_const_part = \\\n",
    "  pd.read_csv('./sensitivity-analysis/const-partition-unroll/summary.csv').sort_values(by='unroll').reset_index()\n",
    "sensitivity_lockstep = \\\n",
    "  pd.read_csv('./sensitivity-analysis/lockstep-partition-and-unroll/summary.csv').sort_values(by='partition').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_sensitivity_plots():\n",
    "    # No partition plot.\n",
    "    print('[Sensitivity Analysis] Generating no partition graphs.')\n",
    "    plots.make_absolute_plots(\n",
    "        sensitivity_no_part,\n",
    "        x_key = 'unroll',\n",
    "        y_keys = ['runtime_avg', 'lut_used'],\n",
    "        group_by = lambda x: 0,\n",
    "        x_label = 'Unrolling factor (no partitioning)',\n",
    "        fig_prefix = 'no-partition-unrolling',\n",
    "        dpi = DPI,\n",
    "        fig_dir = FIG_DIR,\n",
    "        )\n",
    "    \n",
    "    # Constant partitioning\n",
    "    print('[Sensitivity Analysis] Generating constant partition graphs.')\n",
    "    plots.make_sec2_plot(\n",
    "        df=sensitivity_const_part,\n",
    "        x_key='unroll',\n",
    "        x_label = 'Unrolling factor (partitioning = 8)',\n",
    "        factor = 8,\n",
    "        fig_prefix = 'const-partition-unroll',\n",
    "        legend = 'lut_used',\n",
    "        dpi = DPI,\n",
    "        fig_dir = FIG_DIR,\n",
    "    )\n",
    "    \n",
    "    # Lockstep partitioning and unrolling\n",
    "    print('[Sensitivity Analysis] Generating lockstep partition graphs.')\n",
    "    plots.make_sec2_plot(\n",
    "        df=sensitivity_lockstep,\n",
    "        x_key = 'partition',\n",
    "        x_label = 'Partitioning and Unrolling factor',\n",
    "        fig_prefix = 'const-len-partition-and-unroll',\n",
    "        dpi=DPI,\n",
    "        fig_dir = FIG_DIR)\n",
    "\n",
    "\n",
    "make_sensitivity_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "### Qualitative Evaluation (fig 8)\n",
    "\n",
    "The qualitative evaluation consists of parameter sweeps over three MachSuite benchmarks:\n",
    "\n",
    "1. stencil-2d\n",
    "2. md-knn\n",
    "3. md-grid\n",
    "\n",
    "For each benchmark, we generated several configurations and ran estimation for the benchmarks accepted by Dahlia. We **did not** run estimation for all possible configurations--just the ones accepted by Dahlia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_X = {\"scale_fun\": lambda x: float(x / 100), \"scale_label\": \"Hundreds of cycles\"}\n",
    "\n",
    "RESOURCES = ['bram_used', 'dsp48_used', 'ff_used', 'lut_used', 'avg_latency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark files\n",
    "qual_benchs = ['md-knn-summary', 'md-grid-summary', 'stencil2d-inner-summary']\n",
    "\n",
    "# Dataframes with all the data.\n",
    "qual_dfs = { bench_name : pd.read_csv(f\"qualitative-study/data/{bench_name}.csv\") for bench_name in qual_benchs }\n",
    "\n",
    "# Calculate average latencies for each benchmark.\n",
    "for key in qual_benchs:\n",
    "    qual_dfs[key]['avg_latency'] = ((qual_dfs[key]['min_latency'] + qual_dfs[key]['max_latency']) /  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stencil2d():\n",
    "    df = qual_dfs['stencil2d-inner-summary']\n",
    "    res = 'ur_loop2'\n",
    "\n",
    "    opts = find_pareto(df[RESOURCES].to_numpy())\n",
    "    pareto = df.iloc[opts]\n",
    "    \n",
    "    print(f'[Qualitative Study] Accepted Pareto points for stencil2d: {len(pareto)}/{len(df)}')\n",
    "\n",
    "    def group(idx):\n",
    "        return df.iloc[idx][res]\n",
    "\n",
    "    plots.make_qual_plot(\n",
    "        pareto,\n",
    "        x_data = {'key': 'avg_latency', 'label': 'Average Latency'},\n",
    "        y_data = {'key': 'lut_used', 'label': 'LUTs Used'},\n",
    "        group_by = group,\n",
    "        legend=\"Inner Unroll\",\n",
    "        fig_prefix = \"stencil-inner-2d-inner-unroll\",\n",
    "        scale_x = SCALE_X,\n",
    "        fig_dir = FIG_DIR,\n",
    "        dpi=DPI,\n",
    "    )\n",
    "    \n",
    "plot_stencil2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers from md_knn\n",
    "\n",
    "In the graph above, the points on the extreme right trade-off a lot of latency for reducing the LUT count by a bit. In the paper, we decided to not show these points **but we explicitly call this out in the prose of the paper**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_md_knn():\n",
    "    df = qual_dfs['md-knn-summary']\n",
    "    df = df[df.avg_latency < 100000].reset_index()\n",
    "    res = 'ur_loop1'\n",
    "\n",
    "    opts = find_pareto(df[RESOURCES].to_numpy())\n",
    "    pareto = df.iloc[opts]\n",
    "    \n",
    "    print(f'[Qualitative Study] Accepted Pareto points for md-knn: {len(pareto)}/{len(df)}')\n",
    "    \n",
    "    def group(idx):\n",
    "        return df.iloc[idx][res]\n",
    "            \n",
    "    plots.make_qual_plot(\n",
    "        pareto,\n",
    "        x_data = {'key': 'avg_latency', 'label': 'Average Latency'},\n",
    "        y_data = {'key': 'lut_used', 'label': 'LUTs Used'},\n",
    "        group_by = group,\n",
    "        legend='Outer Unroll',\n",
    "        fig_prefix = \"md-knn-outer-unroll\",\n",
    "        scale_x = SCALE_X,\n",
    "        fig_dir = FIG_DIR,\n",
    "        dpi=DPI,\n",
    "    )\n",
    "\n",
    "plot_md_knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_md_grid():\n",
    "    df = qual_dfs['md-grid-summary']\n",
    "    res = 'B0Y_UR'\n",
    "\n",
    "    opts = find_pareto(df[RESOURCES].to_numpy())\n",
    "    pareto = df.iloc[opts]\n",
    "    \n",
    "    print(f'[Qualitative Study] Accepted Pareto points for md-grid: {len(pareto)}/{len(df)}')\n",
    "\n",
    "    def group(idx):\n",
    "        return df.iloc[idx][res]\n",
    "\n",
    "    plots.make_qual_plot(\n",
    "        pareto,\n",
    "        x_data = {'key': 'avg_latency', 'label': 'Average Latency'},\n",
    "        y_data = {'key': 'lut_used', 'label': 'LUTs Used'},\n",
    "        group_by = group,\n",
    "        legend=\"Middle Unroll\",\n",
    "        fig_prefix = \"md-grid-middle-unroll\",\n",
    "        scale_x = SCALE_X,\n",
    "        fig_dir = FIG_DIR,\n",
    "        dpi=DPI,\n",
    "    )\n",
    "    \n",
    "plot_md_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "### Spatial Comparison (fig. 9)\n",
    "\n",
    "Spatial is a high level programming language for designing hardware. In our paper, we sweep over parameters for a general matrix multiply design in Spatial and demonstrate that Spatial automatic parameter inference for banking and unrolling can also generate unpredictable designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_spatial_comp():\n",
    "    pal = sns.color_palette(\"colorblind\",6)\n",
    "\n",
    "    PERF_RESOURCES = ['dsp_used', 'bram_tile_used','lut_used']\n",
    "\n",
    "    df = pd.read_csv('spatial-sweep/data/resource_summary.csv')\n",
    "\n",
    "    # Normalize resource usage against the no unrolling case.\n",
    "    for res in PERF_RESOURCES:\n",
    "        baseline = df[res][0]\n",
    "        df[res + \"_norm\"] = df[res] / baseline\n",
    "            \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    loop_k = np.arange(16)+1\n",
    "    maker = ['X','D','o']\n",
    "    for i, res in enumerate(PERF_RESOURCES):\n",
    "        y = df[res + '_norm']\n",
    "        sns.lineplot(loop_k, y, linewidth=3, marker=maker[i], ms=10)\n",
    "       \n",
    "\n",
    "    plt.xticks(fontsize = 14)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    ax.set_ylabel('Normalized Resource Usages',fontsize= 16)\n",
    "    ax.set_xlabel('Unrolling Factor',fontsize = 16)\n",
    "    \n",
    "    PERF_RESOURCES_NAME = ['DSP used', 'BRAM used', 'LUT used']\n",
    "    ax.legend(PERF_RESOURCES_NAME, prop={'size': 14})\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(FIG_DIR + 'paper-normalized.pdf', bbox_inches='tight', dpi=DPI)\n",
    "\n",
    "\n",
    "plot_spatial_comp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Vega Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from altair import datum\n",
    "from altair_saver import save\n",
    "\n",
    "pareto = exhaustive_pareto_points.bench\n",
    "dahlia = exhaustive_dahlia_points.bench\n",
    "dahlia_pareto = exhaustive_pareto_points[exhaustive_pareto_points.bench.isin(dahlia)].bench\n",
    "\n",
    "pareto_label = 'Pareto'\n",
    "dahlia_label = 'Dahlia'\n",
    "dp_label = 'Dahlia & Pareto'\n",
    "\n",
    "df = exhaustive_dse_points.copy()\n",
    "df['kind'] = 'All'\n",
    "df.loc[df.bench.isin(pareto), 'kind'] = pareto_label\n",
    "df.loc[df.bench.isin(dahlia), 'kind'] = dahlia_label\n",
    "df.loc[df.bench.isin(dahlia_pareto), 'kind'] = dp_label\n",
    "# Counts for all kinds\\\n",
    "df = df[['est_compute_lat', 'kind'] + resources].drop_duplicates()\n",
    "print(alt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alt.data_transformers.enable('data_server')\n",
    "\n",
    "chart = alt.Chart(df).mark_point(size=40, filled=True).encode(\n",
    "    x=alt.X(\n",
    "        axis=alt.Axis(format='~s', title='Latency (cycles)', tickCount=8),\n",
    "        field='est_compute_lat', \n",
    "        type='quantitative',\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        axis=alt.Axis(format='~s', title=None, tickCount=5),\n",
    "        field='est_lut',\n",
    "        type='quantitative',\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        'kind',\n",
    "        # legend=None,\n",
    "        scale=alt.Scale(\n",
    "            domain=['All', dp_label, dahlia_label, pareto_label],\n",
    "            range=['#c5c5c5', '#1b9e77', '#d95f02', '#7570b3'])\n",
    "    ),\n",
    "    opacity=alt.Opacity(\n",
    "        'kind',\n",
    "        # legend=None,\n",
    "        scale=alt.Scale(\n",
    "            domain=['All', dp_label, dahlia_label, pareto_label],\n",
    "            range=[0.3, 1, 1, 1])\n",
    "    ),\n",
    "    shape=alt.Opacity(\n",
    "        'kind',\n",
    "        # legend=None,\n",
    "        scale=alt.Scale(\n",
    "            domain=['All', dp_label, dahlia_label, pareto_label],\n",
    "            range=['circle', 'diamond', 'circle', 'circle'])\n",
    "    ),\n",
    ").properties(\n",
    "    width=450,\n",
    ")\n",
    "\n",
    "\n",
    "def set_style(chart, suppress_y=False):\n",
    "    return chart.configure_view(\n",
    "        strokeWidth=0\n",
    "    ).configure_legend(\n",
    "        titleFontSize=15,\n",
    "        labelFontSize=14,\n",
    "        title=None,\n",
    "        orient='top-right',\n",
    "        # disable=True,\n",
    "    ).configure_axis(\n",
    "        grid=False,\n",
    "        labelFontSize=15,\n",
    "        titleFontSize=15,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = chart.mark_circle(size=15).encode(\n",
    "    y=alt.Y(\n",
    "        axis=alt.Axis(format='~s', title='LUTs used', tickCount=5),\n",
    "        field='est_lut',\n",
    "        type='quantitative',\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        'kind',\n",
    "        scale=alt.Scale(\n",
    "            domain=['All', dp_label, dahlia_label, pareto_label],\n",
    "            range=['#c5c5c5', '#1b9e77', '#d95f02', '#7570b3'])\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig1 = base.transform_filter((datum.kind == 'All')) + \\\n",
    "    base.mark_circle(size=20).transform_filter((datum.kind == pareto_label))\n",
    "\n",
    "res = set_style(fig1)\n",
    "res.save('dse-pareto.svg')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = chart.mark_circle(size=15).transform_filter((datum.kind == 'All')) + \\\n",
    "    chart.mark_circle(size=20).transform_filter((datum.kind == dahlia_label))\n",
    "\n",
    "\n",
    "res = set_style(fig2)\n",
    "res.save('dse-dahlia.svg')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = chart.transform_filter((datum.est_compute_lat < 1600000) & (datum.est_lut < 40000)).encode(\n",
    "    x=alt.X(\n",
    "        axis=alt.Axis(format='~s', title='Latency (cycles)'),\n",
    "        field='est_compute_lat', \n",
    "        type='quantitative',\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig3 = small.transform_filter((datum.kind == 'All')) + \\\n",
    "    small.transform_filter((datum.kind != \"All\")) + \\\n",
    "    small.mark_circle(size=60).transform_filter((datum.kind == dp_label))\n",
    "\n",
    "res = set_style(fig3)\n",
    "res.save('dse-zoom.svg')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qual_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stencil_2d = qual_dfs['stencil2d-inner-summary']\n",
    "s2d = stencil_2d.iloc[find_pareto(stencil_2d[RESOURCES].to_numpy())]\n",
    "s2d_chart = alt.Chart(s2d).mark_point(size=200, filled=True).encode(\n",
    "    x=alt.X(\n",
    "        axis=alt.Axis(format='~s', title='Latency (cycles)', tickCount=8),\n",
    "        field='avg_latency', \n",
    "        type='quantitative',\n",
    "        scale=alt.Scale(domain=(50000,300000))\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        axis=alt.Axis(format='~s', title = \"LUTs used\", tickCount=5),\n",
    "        field='lut_used',\n",
    "        type='quantitative',\n",
    "        scale=alt.Scale(domain=(2000,6000))\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        'ur_loop2',\n",
    "        legend=alt.Legend(title=\"Inner unroll\", orient='top-right'),\n",
    "        scale=alt.Scale(\n",
    "            domain=[1, 3],\n",
    "            range=['#1b9e77', '#d95f02']),\n",
    "        type='ordinal'\n",
    "    ),\n",
    ").properties(\n",
    "    width=400,\n",
    ")\n",
    "\n",
    "res = set_style(s2d_chart)\n",
    "res.save('stencil2d-inner.svg')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_knn = qual_dfs['md-knn-summary']\n",
    "md_knn_p = md_knn.iloc[find_pareto(md_knn[RESOURCES].to_numpy())]\n",
    "md_knn_chart = alt.Chart(md_knn_p).mark_point(size=200, filled=True).encode(\n",
    "    x=alt.X(\n",
    "        axis=alt.Axis(format='~s', title='Latency (cycles)', tickCount=3),\n",
    "        field='avg_latency', \n",
    "        type='quantitative',\n",
    "        scale=alt.Scale(domain=(16000,18200))\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        axis=alt.Axis(format='~s', title = None, tickCount=5),\n",
    "        field='lut_used',\n",
    "        type='quantitative',\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        'ur_loop1',\n",
    "        legend=None,\n",
    "        scale=alt.Scale(scheme = 'dark2'),\n",
    "        type='ordinal'\n",
    "    ),\n",
    ").properties(\n",
    "    width=220,\n",
    ")\n",
    "\n",
    "alt.Resolve(scale=alt.LegendResolveMap(color=alt.ResolveMode('independent')))\n",
    "\n",
    "md_knn_both = (md_knn_chart.transform_filter(datum.avg_latency < 100000) | \\\n",
    "md_knn_chart.transform_filter(datum.avg_latency > 100000).encode(\n",
    "    x=alt.X(\n",
    "        axis=alt.Axis(format='~s', title='Latency (cycles)', tickCount=3),\n",
    "        field='avg_latency', \n",
    "        type='quantitative',\n",
    "        scale=alt.Scale(domain=(128550,128800))\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        axis=alt.Axis(format='~s', title = None, tickCount=5),\n",
    "        field='lut_used',\n",
    "        type='quantitative',\n",
    "        scale=alt.Scale(domain=(8000,12000))\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        'ur_loop1',\n",
    "        legend=alt.Legend(title=\"Outer unroll\", orient='top-right'),\n",
    "        scale=alt.Scale(scheme = 'dark2'),\n",
    "        type='ordinal'\n",
    "    ),\n",
    "\n",
    ")).resolve_legend('independent')#.resolve_axis(x='shared')\n",
    "res = set_style(md_knn_both)\n",
    "res.save('md-knn.svg')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_grid = qual_dfs['md-grid-summary']\n",
    "md_grid_p = md_grid.iloc[find_pareto(md_grid[RESOURCES].to_numpy())]\n",
    "md_grid_chart = alt.Chart(md_grid_p).mark_point(size=200, filled=True).encode(\n",
    "    x=alt.X(\n",
    "        axis=alt.Axis(title='Latency (cycles)', tickCount=3),\n",
    "        field='avg_latency', \n",
    "        type='quantitative',\n",
    "        scale=alt.Scale(domain=(7940,8045))\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        axis=alt.Axis(format=\"~s\", title = None, tickCount=6),\n",
    "        field='lut_used',\n",
    "        type='quantitative',\n",
    "        scale=alt.Scale(domain=(10000,50000))\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        'B0Y_UR',\n",
    "        legend=alt.Legend(title=\"Middle unroll\", orient='top-right'),\n",
    "        scale=alt.Scale(\n",
    "            scheme = 'dark2',\n",
    "        ),\n",
    "        type='ordinal'\n",
    "    ),\n",
    ").properties(\n",
    "    width=400,\n",
    ")\n",
    "\n",
    "res = set_style(md_grid_chart)\n",
    "res.save('md-grid.svg')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
